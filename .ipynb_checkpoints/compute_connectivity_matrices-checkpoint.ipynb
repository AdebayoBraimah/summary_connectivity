{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages/modules\n",
    "import subprocess\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import platform\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google style guide:\n",
    "# https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html\n",
    "#\n",
    "# Numpy style guide:\n",
    "# https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html#example-numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Command(object):\n",
    "    '''Creates a command and an empty command list for UNIX command line programs/applications. Primary use and\n",
    "    use-cases are intended for the subprocess module and its associated classes (i.e. Popen/call/run).\n",
    "    \n",
    "    Attributes (class and instance attributes):\n",
    "        command (instance): Command to be performed on the command line.\n",
    "        cmd_list (instance): Mutable list that can be appended to.\n",
    "    \n",
    "    Modules/Packages required:\n",
    "        - os\n",
    "        - logging\n",
    "        - subprocess\n",
    "    '''\n",
    "\n",
    "    def __init__(self,command):\n",
    "        '''Init doc-string for Command class. Initializes a command to be used on UNIX command line.\n",
    "        The input argument is a command (string), and a mutable list is returned (, that can later\n",
    "        be appended to).\n",
    "        \n",
    "        Usage:\n",
    "            echo = Command(\"echo\")\n",
    "            echo.cmd_list.append(\"Hi!\")\n",
    "            echo.cmd_list.append(\"I have arrived!\")\n",
    "        \n",
    "        Arguments:\n",
    "            command (string): Command to be used. Note: command used must be in system path\n",
    "        Returns:\n",
    "            cmd_list (list): Mutable list that can be appended to.\n",
    "        '''\n",
    "        self.command = command\n",
    "        self.cmd_list = [f\"{self.command}\"]\n",
    "        \n",
    "    def log(self,log_file=\"log_file.log\",log_cmd=\"\"):\n",
    "        '''Log function for logging commands and messages to some log file.\n",
    "        \n",
    "        Usage:\n",
    "            # Initialize the `log` function command\n",
    "            log_msg = Command(\"log\")\n",
    "            \n",
    "            # Specify output file and message\n",
    "            log_msg.log(\"sub.log\",\"test message 1\")\n",
    "            \n",
    "            # Record message, however - no need to re-initialize `log` funcion command or log output file\n",
    "            log_msg.log(\"test message 2\")\n",
    "        \n",
    "        NOTE: The input `log_file` only needs to be specified once. Once specified,\n",
    "            this log is written to each time this or the `run` function is invoked.\n",
    "        \n",
    "        Arguments:\n",
    "            log_file (file): Log file to be written to. \n",
    "            log_cmd (str): Message to be written to log file.\n",
    "        '''\n",
    "        \n",
    "        # Set-up logging to file\n",
    "        logging.basicConfig(level=logging.INFO,\n",
    "                            format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
    "                            datefmt='%d-%m-%y %H:%M:%S',\n",
    "                            filename=log_file,\n",
    "                            filemode='a')\n",
    "        \n",
    "        # Define a Handler which writes INFO messages or higher to the sys.stderr\n",
    "        console = logging.StreamHandler()\n",
    "        console.setLevel(logging.INFO)\n",
    "        \n",
    "        # Add the handler to the root logger\n",
    "        logging.getLogger().addHandler(console)\n",
    "        \n",
    "        # Define logging\n",
    "        logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Log command/message\n",
    "        logger.info(f\"{log_cmd}\")\n",
    "        \n",
    "    def run(self,log_file=\"\",debug=False,dryrun=False,env=None,stdout=\"\",shell=False):\n",
    "        '''Uses python's built-in subprocess class to execute (run) a command from an input command list.\n",
    "        The standard output and error can optionally be written to file.\n",
    "        \n",
    "        Usage:\n",
    "            echo.run() # This will return tuple (returncode,log,None,None), but will echo \"Hi!\" to screen.\n",
    "            \n",
    "        NOTE: \n",
    "            - The contents of the 'stdout' output file will be empty if 'shell' is set to True.\n",
    "            - Once the log file name 'log_file' has been set, that value is stored and cannot be changed.\n",
    "                - This log file will continue to be appended to for each invocation of this class.\n",
    "        Arguments:\n",
    "            log_file (file): Output log file name.\n",
    "            debug (bool): Sets logging function verbosity to DEBUG level.\n",
    "            dryrun (bool): Dry run -- does not run task. Command is recorded to log file.\n",
    "            env (dict): Dictionary of environment variables to add to subshell.\n",
    "            stdout (file): Output file to write standard output to.\n",
    "            shell (bool): Use shell to execute command.\n",
    "            \n",
    "        Returns:\n",
    "            p.returncode (int): Return code for command execution should the 'log_file' option be used.\n",
    "            log_file (file): Output log file with appended information should the 'log_file' option be used.\n",
    "            stdout (file): Standard output writtent to file should the 'stdout' option be used.\n",
    "            stderr (file): Standard error writtent to file should the 'stdout' option be used.\n",
    "        '''\n",
    "        \n",
    "        # Define logging\n",
    "        logger = logging.getLogger(__name__)\n",
    "        cmd = ' '.join(self.cmd_list) # Join list for logging purposes\n",
    "        \n",
    "        if debug:\n",
    "            logger.debug(f\"Running: {cmd}\")\n",
    "        else:\n",
    "            logger.info(f\"Running: {cmd}\")\n",
    "        \n",
    "        if dryrun:\n",
    "            logger.info(\"Performing command as dryrun\")\n",
    "            return 0\n",
    "        \n",
    "        # Define environment variables\n",
    "        merged_env = os.environ\n",
    "        if env:\n",
    "            merged_env.update(env)\n",
    "        \n",
    "        # Execute/run command\n",
    "        p = subprocess.Popen(self.cmd_list,shell=shell,env=merged_env,\n",
    "                        stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "\n",
    "        # Write log files\n",
    "        out,err = p.communicate()\n",
    "        out = out.decode('utf-8')\n",
    "        err = err.decode('utf-8')\n",
    "\n",
    "        # Write std output/error files\n",
    "        if stdout:\n",
    "            stderr = os.path.splitext(stdout)[0] + \".err\"\n",
    "            with open(stdout,\"w\") as f_out:\n",
    "                with open(stderr,\"w\") as f_err:\n",
    "                    f_out.write(out)\n",
    "                    f_err.write(err)\n",
    "                    f_out.close(); f_err.close()\n",
    "        else:\n",
    "            stdout = None\n",
    "            stderr = None\n",
    "\n",
    "        if p.returncode:\n",
    "            logger.error(f\"command: {cmd} \\n Failed with returncode {p.returncode}\")\n",
    "\n",
    "        if len(out) > 0:\n",
    "            if debug:\n",
    "                logger.debug(out)\n",
    "            else:\n",
    "                logger.info(out)\n",
    "\n",
    "        if len(err) > 0:\n",
    "            if debug:\n",
    "                logger.info(err)\n",
    "            else:\n",
    "                logger.warning(err)\n",
    "        return p.returncode,log_file,stdout,stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cii_clusters(cii_file,\n",
    "                      out_file,\n",
    "                      left_surf,\n",
    "                      right_surf,\n",
    "                      thresh,\n",
    "                      min_size,\n",
    "                      log_file=\"\",\n",
    "                      debug=False,\n",
    "                      dryrun=False,\n",
    "                      env=None,\n",
    "                      stdout=\"\",\n",
    "                      shell=False):\n",
    "    '''Finds cluster in a CIFTI file.\n",
    "    \n",
    "    Args:\n",
    "        cii_file (CIFTI file, str): Input CIFTI file.\n",
    "        out_file (file, str): Output CIFTI file name (including file extension).\n",
    "        left_surf (GIFTI file, str): Input left group surface GIFTI file.\n",
    "        right_surf (GIFTI file, str): Input right group surface GIFTI file.\n",
    "        thresh (float): Threshold all values below this value.\n",
    "        min_size (int): Threshold for surface area and volume.\n",
    "        log_file (file, str): Log file name.\n",
    "        debug (bool): Sets logging function verbosity to DEBUG level.\n",
    "        dryrun (bool): Dry run -- does not run task. Command is recorded to log file.\n",
    "        env (dict): Dictionary of environment variables to add to subshell.\n",
    "        stdout (file, str): Output file to write standard output to.\n",
    "        shell (bool): Use shell to execute command.\n",
    "    \n",
    "    Returns:\n",
    "        out_file (CIFTI file, str): Output CIFTI file with clusters.\n",
    "    \n",
    "    Raises:\n",
    "        TypeError: `thresh` should be float, and `min_size` should int.\n",
    "    '''\n",
    "    \n",
    "    # Check input values\n",
    "    if type(thresh) != float and type(thresh) != int:\n",
    "        raise TypeError(f\"Input value for thresh arg is a {type(thresh)} not a float or an int.\")\n",
    "        sys.exit(1)\n",
    "    if type(min_size) != float and type(min_size) != int:\n",
    "        raise TypeError(f\"Input value for min_size arg is a {type(min_size)} not a float or an int.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Convert int to str\n",
    "    thresh = str(thresh)\n",
    "    min_size = str(min_size)\n",
    "    \n",
    "    # Init UNIX command\n",
    "    find_clusters = Command(\"wb_command\")\n",
    "    find_clusters.cmd_list.append(\"-cifti-find-clusters\")\n",
    "    find_clusters.cmd_list.append(cii_file)\n",
    "    find_clusters.cmd_list.append(thresh)\n",
    "    find_clusters.cmd_list.append(min_size)\n",
    "    find_clusters.cmd_list.append(thresh)\n",
    "    find_clusters.cmd_list.append(min_size)\n",
    "    find_clusters.cmd_list.append(\"COLUMN\")\n",
    "    find_clusters.cmd_list.append(out_file)\n",
    "    find_clusters.cmd_list.append(\"-left-surface\")\n",
    "    find_clusters.cmd_list.append(left_surf)\n",
    "    find_clusters.cmd_list.append(\"-right-surface\")\n",
    "    find_clusters.cmd_list.append(right_surf)\n",
    "    \n",
    "    # execute command\n",
    "    [exit_status,log_file,stdout,stderr] = find_clusters.run(log_file,\n",
    "                                                             debug=debug,\n",
    "                                                             dryrun=dryrun,\n",
    "                                                             env=env,\n",
    "                                                             stdout=stdout,\n",
    "                                                             shell=shell)\n",
    "\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifti_to_nifti(cii,out,log_file=\"\",debug=False,dryrun=False,env=None,stdout=\"\",shell=False):\n",
    "    '''Performs conversion of input CIFTI-2 file to NIFTI-1 file via\n",
    "    wb_command -cifti-convert.\n",
    "    \n",
    "    Arguments:\n",
    "        cii (file): Input CIFTI-2 file.\n",
    "        out (file): Output file name for NIFTI-1 file.\n",
    "        log_file (log): Log file to be written to. \n",
    "            - NOTE: if the log function has been used previously, then this argument need not be assigned.\n",
    "        debug (bool): Turn on logging's diagnostic messaging.\n",
    "        dryrun (bool): Perform dryrun (i.e. does not generate any files).\n",
    "        env (dict): Dictionary of environmental variables.\n",
    "        stdout (file): Standard output file to be written to.\n",
    "            - NOTE: This file can only be written to if `shell` is set to False.\n",
    "        shell (bool): Run the command using a shell.\n",
    "        \n",
    "    Returns:\n",
    "        out(file): Output file name for NIFTI-1 file.\n",
    "    '''\n",
    "    \n",
    "    # Format variable\n",
    "    if '.nii.gz' not in out:\n",
    "        out = out + \".nii.gz\"\n",
    "    \n",
    "    # Init UNIX command\n",
    "    cii_to_nii = Command(\"wb_command\")\n",
    "    cii_to_nii.cmd_list.append(\"-cifti-convert\")\n",
    "    cii_to_nii.cmd_list.append(\"-to-nifti\")\n",
    "    cii_to_nii.cmd_list.append(f\"{cii}\")\n",
    "    cii_to_nii.cmd_list.append(f\"{out}\")\n",
    "    \n",
    "    # Execute command\n",
    "    [exit_status,log_file,stdout,stderr] = cii_to_nii.run(log_file=log_file,\n",
    "                                                          debug=debug,\n",
    "                                                          dryrun=dryrun,\n",
    "                                                          env=env,\n",
    "                                                          stdout=stdout,\n",
    "                                                          shell=shell)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meants(nii,out,label,log_file=\"\",debug=False,dryrun=False,env=None,stdout=\"\",shell=False,verbose=False):\n",
    "    '''Performs mean timeseries extraction from 4D timeseries using mask/label\n",
    "    file.\n",
    "    \n",
    "    Arguments:\n",
    "        nii (file): Input NIFTI-1 file\n",
    "        out (file): Output file name for NIFTI-1 mean timeseries\n",
    "        label (file): Input NIFTI-1 label file (dimensions must match input NIFTI-1 file)\n",
    "        log_file (log): Log file to be written to. \n",
    "            - NOTE: if the log function has been used previously, then this argument need not be assigned.\n",
    "        debug (bool): Turn on logging's diagnostic messaging\n",
    "        dryrun (bool): Perform dryrun (i.e. does not generate any files)\n",
    "        env (dict): Dictionary of environmental variables\n",
    "        stdout (file): Standard output file to be written to.\n",
    "            - NOTE: This file can only be written to if `shell` is set to False.\n",
    "        shell (bool): Run the command using a shell.\n",
    "        verbose (bool): Turn on verbose/diagnostic messages for UNIX command\n",
    "    Returns:\n",
    "        out(file): Output file name for NIFTI-1 file\n",
    "    '''\n",
    "    \n",
    "    # Format variable\n",
    "    if '.txt' not in out:\n",
    "        out = out + \".txt\"\n",
    "    \n",
    "    # Init UNIX command\n",
    "    mean_ts = Command(\"fslmeants\")\n",
    "    mean_ts.cmd_list.append(\"-i\"); mean_ts.cmd_list.append(f\"{nii}\")\n",
    "    mean_ts.cmd_list.append(\"-o\"); mean_ts.cmd_list.append(f\"{out}\")\n",
    "    mean_ts.cmd_list.append(f\"--label={label}\")\n",
    "    # mean_ts.cmd_list.append(f\"{label}\")\n",
    "    \n",
    "    if verbose:\n",
    "        mean_ts.cmd_list.append(\"--verbose\")\n",
    "    \n",
    "    # Execute command \n",
    "    [exit_status,log_file,stdout,stderr] = mean_ts.run(log_file=log_file,\n",
    "                                                      debug=debug,\n",
    "                                                      dryrun=dryrun,\n",
    "                                                      env=env,\n",
    "                                                      stdout=stdout,\n",
    "                                                      shell=shell)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_corr(file1,log_file=\"\"):\n",
    "    '''Computes Pearson correlation for a N x M matrix/array\n",
    "    that is stored as a text file.\n",
    "    \n",
    "    Arguments:\n",
    "        file1 (file): Input file containing N x M matrix\n",
    "        log_file (log): Log file to be written to. \n",
    "        \n",
    "    Returns:\n",
    "        Pearson correlation coefficient (float): Pearson correlation coefficients.\n",
    "    '''\n",
    "    \n",
    "    # Log message\n",
    "    log_msg = Command(\"log\")\n",
    "    log_msg.log(log_file=log_file,\n",
    "                log_cmd=\"Computing Pearson correlation\")\n",
    "    \n",
    "    # Load files\n",
    "    A = np.loadtxt(file1)\n",
    "    \n",
    "    # Compute Pearson correlation (assumes A is N x N matrix)\n",
    "    a = np.corrcoef(A,rowvar=False)\n",
    "    \n",
    "    # Retain lower triangular of correlation matrix,\n",
    "    # offset by -1 to exclude main diagonal\n",
    "    return a[np.tril_indices(len(a),k=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_arr(arr,out_file):\n",
    "    '''Writes numpy array to file.\n",
    "    \n",
    "    Args:\n",
    "        arr (:obj: `numpy array` of `floats`): Numpy array of values.\n",
    "        out_file (file, `str`): Output file name.\n",
    "    \n",
    "    Returns:\n",
    "        out_file (file, `str`): Output file containing array information.\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        out_file = np.savetxt(out_file,arr,fmt=\"%.4f\")\n",
    "    except ValueError:\n",
    "        with open(out_file,\"w\") as file:\n",
    "            file.write(f\"{arr:4f}\\n\")\n",
    "            file.close()\n",
    "            \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_comp_multi_roi(cii,\n",
    "                        labels,\n",
    "                        out_prefixes,\n",
    "                        left_surf,\n",
    "                        right_surf,\n",
    "                        thresh=0,\n",
    "                        min_size=0,\n",
    "                        log_file=\"\",\n",
    "                        debug=False,\n",
    "                        dryrun=False,\n",
    "                        env=None,\n",
    "                        stdout=\"\",\n",
    "                        verbose=False,\n",
    "                        shell=False):\n",
    "    '''Computes 'connectivity score' of a network or networks by computing the\n",
    "    mean timeseries from each cluster of greyordinates within the network and\n",
    "    computing the Pearson correlation between each set of clusters for each network.\n",
    "    \n",
    "    Additionally, should more than one network be used as input, then the mean connectivity\n",
    "    is also collectively computed between all clusters/ROIs.\n",
    "    \n",
    "    Output files include:\n",
    "        - Output prefixed files for each network/ROI.\n",
    "        - Connectivity score for all networks.\n",
    "            - Appended with 'all_labels.mean_corr.txt'\n",
    "            - Only applicable when more than network is used as input\n",
    "            \n",
    "    Args:\n",
    "        cii_file (CIFTI file, str): Input CIFTI file.\n",
    "        labels (:obj:`list` of :obj:`str`): List of label/network/ROI CIFTI files to mask input CIFTI timeseries.\n",
    "        out_prefixes (:obj:`list` of :obj:`str`): Corresponding output prefixes for each input CIFTI label mask.\n",
    "        left_surf (GIFTI file, str): Input left group surface GIFTI file.\n",
    "        right_surf (GIFTI file, str): Input right group surface GIFTI file.\n",
    "        thresh (float): Threshold all values below this value.\n",
    "        min_size (int): Threshold for surface area and volume.\n",
    "        log_file (file, str): Log file name.\n",
    "        debug (bool): Sets logging function verbosity to DEBUG level.\n",
    "        dryrun (bool): Dry run -- does not run task. Command is recorded to log file.\n",
    "        env (dict): Dictionary of environment variables to add to subshell.\n",
    "        stdout (file, str): Output file to write standard output to.\n",
    "        shell (bool): Use shell to execute command.\n",
    "    '''\n",
    "    \n",
    "    # Check input list length\n",
    "    if len(labels) != len(out_prefixes):\n",
    "        raise IndexError(\"Input lists `lables` and `out_prefixes` are of different lengths\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Ascertain absolute file paths\n",
    "    cii = os.path.abspath(cii)\n",
    "    labels = [ os.path.abspath(label) for label in labels ]\n",
    "    log_file = os.path.abspath(log_file)\n",
    "    \n",
    "    out_dir = os.path.abspath(os.path.dirname(out_prefixes[0]))\n",
    "    out_names = [ os.path.basename(out_prefix) for out_prefix in out_prefixes ]\n",
    "    \n",
    "    # Create temporary directory\n",
    "    cwd = os.getcwd()\n",
    "    n = 10000 # maximum N for random number generator\n",
    "    tmp_dir = os.path.join(out_dir, 'tmp_dir_' + str(random.randint(0, n)))\n",
    "    \n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir)\n",
    "        \n",
    "    os.chdir(tmp_dir)\n",
    "    \n",
    "    # Log message\n",
    "    log_msg = Command(\"log\")\n",
    "    log_msg.log(log_file=log_file,\n",
    "                log_cmd=f\"Input Timeseries: {os.path.basename(cii)}\")\n",
    "    [ log_msg.log(log_file=log_file, \n",
    "                 log_cmd=f\"Processing CIFTI label file: {os.path.basename(label)}\") for label in labels ]\n",
    "    \n",
    "    log_msg.log(log_file=log_file,\n",
    "                log_cmd=\"Creating temporary directory\")\n",
    "    \n",
    "    # convert subject data to NIFTI-1\n",
    "    if verbose:\n",
    "        print(\"Processing: Input Subject NIFTI-2 data\")\n",
    "        log_msg.log(log_file=log_file,\n",
    "                log_cmd=\"Processing: Input Subject NIFTI-2 data\")\n",
    "        \n",
    "    nii_sub = cifti_to_nifti(cii=cii,\n",
    "                             out=\"sub_nii.ts.txt\",\n",
    "                             log_file=log_file,\n",
    "                             debug=debug,\n",
    "                             dryrun=dryrun,\n",
    "                             env=env,\n",
    "                             stdout=\"\",\n",
    "                             shell=shell)\n",
    "    \n",
    "    # Iterate through label/network/ROI files\n",
    "    for idx in enumerate(labels):\n",
    "        i = idx[0]\n",
    "        cii_cluster = f\"out.tmp.{str(i)}.cluster.dscalar.nii\"\n",
    "        nii_cluster = f\"out.tmp.{str(i)}.cluster.nii.gz\"\n",
    "        ts_cluster = f\"out.tmp.{str(i)}.ts.txt\"\n",
    "        out = os.path.join(out_dir,out_names[i] + \".mean_corr.txt\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Processing: {labels[i]}\")\n",
    "            log_msg.log(log_file=log_file,\n",
    "                log_cmd=f\"Processing: {labels[i]}\")\n",
    "        \n",
    "        cii_cluster = find_cii_clusters(cii_file=labels[i],\n",
    "                                        out_file=cii_cluster,\n",
    "                                        left_surf=left_surf,\n",
    "                                        right_surf=right_surf,\n",
    "                                        thresh=thresh,\n",
    "                                        min_size=min_size,\n",
    "                                        log_file=log_file,\n",
    "                                        debug=debug,\n",
    "                                        dryrun=dryrun,\n",
    "                                        env=env,\n",
    "                                        stdout=\"\",\n",
    "                                        shell=shell)\n",
    "        \n",
    "        nii_cluster = cifti_to_nifti(cii=cii_cluster,\n",
    "                                     out=nii_cluster,\n",
    "                                     log_file=log_file,\n",
    "                                     debug=debug,\n",
    "                                     dryrun=dryrun,\n",
    "                                     env=env,\n",
    "                                     stdout=\"\",\n",
    "                                     shell=shell)\n",
    "        \n",
    "        ts_cluster = meants(nii=nii_sub,\n",
    "                            out=ts_cluster,\n",
    "                            label=nii_cluster,\n",
    "                            log_file=log_file,\n",
    "                            debug=debug,\n",
    "                            dryrun=dryrun,\n",
    "                            env=env,\n",
    "                            stdout=\"\",\n",
    "                            shell=shell,\n",
    "                            verbose=verbose)\n",
    "        corr_mat = pearson_corr(file1=ts_cluster,log_file=log_file)\n",
    "        out = write_arr(arr=np.mean(corr_mat),out_file=out)\n",
    "        \n",
    "    if len(labels) > 1:\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Processing connectivity for all input labels\")\n",
    "            log_msg.log(log_file=log_file,\n",
    "                log_cmd=\"Processing connectivity for all input labels\")\n",
    "            \n",
    "        out = os.path.join(out_dir,\"all_labels.mean_corr.txt\")\n",
    "        ts_list = []\n",
    "        \n",
    "        for idx in enumerate(labels):\n",
    "            ts_cluster = f\"out.tmp.{str(i)}.ts.txt\"\n",
    "            ts_mat = np.loadtxt(fname=ts_cluster)\n",
    "            ts_list.append(ts_mat)\n",
    "            \n",
    "        ts_matrix = np.concatenate(ts_list,axis=1)\n",
    "        corr_mat = pearson_corr(file1=ts_cluster,log_file=log_file)\n",
    "        out = write_arr(arr=np.mean(corr_mat),out_file=out)\n",
    "        \n",
    "    # Clean-up\n",
    "    os.chdir(cwd)\n",
    "    log_msg.log(log_file=log_file,\n",
    "                    log_cmd=\"Temporory directory and file clean-up\")\n",
    "    shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input test files\n",
    "networks = [ 'default_mode.network.dscalar.nii', 'attention.network.dscalar.nii', 'orienting.network.dscalar.nii' ]\n",
    "out_prefs = [ 'test/DMN', 'test/attn', 'test/orient' ]\n",
    "sub = os.path.abspath('sub-1003_ses-001_REST_agg_Atlas_s4.dtseries.nii')\n",
    "left_surf = os.path.abspath('templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii')\n",
    "right_surf = os.path.abspath('templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii')\n",
    "thresh = 1\n",
    "min_size = 20\n",
    "log_file = 'test/sub-1003.test.log'\n",
    "out_cii_1 = 'DMN.dscalar.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory variables\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input Timeseries: sub-1003_ses-001_REST_agg_Atlas_s4.dtseries.nii\n",
      "Processing CIFTI label file: default_mode.network.dscalar.nii\n",
      "Processing CIFTI label file: default_mode.network.dscalar.nii\n",
      "Processing CIFTI label file: attention.network.dscalar.nii\n",
      "Processing CIFTI label file: attention.network.dscalar.nii\n",
      "Processing CIFTI label file: attention.network.dscalar.nii\n",
      "Processing CIFTI label file: orienting.network.dscalar.nii\n",
      "Processing CIFTI label file: orienting.network.dscalar.nii\n",
      "Processing CIFTI label file: orienting.network.dscalar.nii\n",
      "Processing CIFTI label file: orienting.network.dscalar.nii\n",
      "Creating temporary directory\n",
      "Creating temporary directory\n",
      "Creating temporary directory\n",
      "Creating temporary directory\n",
      "Creating temporary directory\n",
      "Running: wb_command -cifti-convert -to-nifti /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/sub-1003_ses-001_REST_agg_Atlas_s4.dtseries.nii sub_nii.ts.txt.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/sub-1003_ses-001_REST_agg_Atlas_s4.dtseries.nii sub_nii.ts.txt.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/sub-1003_ses-001_REST_agg_Atlas_s4.dtseries.nii sub_nii.ts.txt.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/sub-1003_ses-001_REST_agg_Atlas_s4.dtseries.nii sub_nii.ts.txt.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/sub-1003_ses-001_REST_agg_Atlas_s4.dtseries.nii sub_nii.ts.txt.nii.gz\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/default_mode.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.0.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/default_mode.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.0.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/default_mode.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.0.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/default_mode.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.0.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/default_mode.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.0.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.0.cluster.dscalar.nii out.tmp.0.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.0.cluster.dscalar.nii out.tmp.0.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.0.cluster.dscalar.nii out.tmp.0.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.0.cluster.dscalar.nii out.tmp.0.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.0.cluster.dscalar.nii out.tmp.0.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.0.ts.txt --label=out.tmp.0.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.0.ts.txt --label=out.tmp.0.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.0.ts.txt --label=out.tmp.0.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.0.ts.txt --label=out.tmp.0.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.0.ts.txt --label=out.tmp.0.cluster.nii.gz\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/attention.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.1.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/attention.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.1.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/attention.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.1.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/attention.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.1.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/attention.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.1.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/attention.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.1.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.1.cluster.dscalar.nii out.tmp.1.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.1.cluster.dscalar.nii out.tmp.1.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.1.cluster.dscalar.nii out.tmp.1.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.1.cluster.dscalar.nii out.tmp.1.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.1.cluster.dscalar.nii out.tmp.1.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.1.cluster.dscalar.nii out.tmp.1.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.1.ts.txt --label=out.tmp.1.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.1.ts.txt --label=out.tmp.1.cluster.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.1.ts.txt --label=out.tmp.1.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.1.ts.txt --label=out.tmp.1.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.1.ts.txt --label=out.tmp.1.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.1.ts.txt --label=out.tmp.1.cluster.nii.gz\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/orienting.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.2.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/orienting.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.2.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/orienting.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.2.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/orienting.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.2.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/orienting.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.2.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/orienting.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.2.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-find-clusters /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/orienting.network.dscalar.nii 1 20 1 20 COLUMN out.tmp.2.cluster.dscalar.nii -left-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii -right-surface /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/templates/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.2.cluster.dscalar.nii out.tmp.2.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.2.cluster.dscalar.nii out.tmp.2.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.2.cluster.dscalar.nii out.tmp.2.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.2.cluster.dscalar.nii out.tmp.2.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.2.cluster.dscalar.nii out.tmp.2.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.2.cluster.dscalar.nii out.tmp.2.cluster.nii.gz\n",
      "Running: wb_command -cifti-convert -to-nifti out.tmp.2.cluster.dscalar.nii out.tmp.2.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.2.ts.txt --label=out.tmp.2.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.2.ts.txt --label=out.tmp.2.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.2.ts.txt --label=out.tmp.2.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.2.ts.txt --label=out.tmp.2.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.2.ts.txt --label=out.tmp.2.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.2.ts.txt --label=out.tmp.2.cluster.nii.gz\n",
      "Running: fslmeants -i sub_nii.ts.txt.nii.gz -o out.tmp.2.ts.txt --label=out.tmp.2.cluster.nii.gz\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Computing Pearson correlation\n",
      "Temporory directory and file clean-up\n",
      "Temporory directory and file clean-up\n",
      "Temporory directory and file clean-up\n",
      "Temporory directory and file clean-up\n",
      "Temporory directory and file clean-up\n",
      "Temporory directory and file clean-up\n",
      "Temporory directory and file clean-up\n",
      "Temporory directory and file clean-up\n",
      "Temporory directory and file clean-up\n",
      "Temporory directory and file clean-up\n"
     ]
    }
   ],
   "source": [
    "corr_comp_multi_roi(cii=sub,\n",
    "                    labels=networks,\n",
    "                    out_prefixes=out_prefs,\n",
    "                    left_surf=left_surf,\n",
    "                    right_surf=right_surf,\n",
    "                    thresh=thresh,\n",
    "                    min_size=min_size,\n",
    "                    log_file=log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = 'default_mode.network.dscalar.nii'\n",
    "l2 = 'attention.network.dscalar.nii'\n",
    "l3 = 'orienting.network.dscalar.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ l1, l2, l3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ os.path.abspath(label) for label in labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/default_mode.network.dscalar.nii',\n",
       " '/mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/attention.network.dscalar.nii',\n",
       " '/mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/orienting.network.dscalar.nii']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default_mode.network.dscalar.nii',\n",
       " 'attention.network.dscalar.nii',\n",
       " 'orienting.network.dscalar.nii']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_names = [ os.path.basename(label) for label in labels ]\n",
    "out_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [ f\"Processing CIFTI label file: {label} \\n\" for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Processing CIFTI label file: /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/default_mode.network.dscalar.nii \\n',\n",
       " 'Processing CIFTI label file: /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/attention.network.dscalar.nii \\n',\n",
       " 'Processing CIFTI label file: /mnt/c/Users/smart/Desktop/CAP/data.cluster.timeseries/orienting.network.dscalar.nii \\n']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub-1003.test.log'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cii = sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log message\n",
    "log_msg = Command(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_msg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1544709e2077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m log_msg.log(log_file=log_file,\n\u001b[0m\u001b[1;32m      2\u001b[0m             log_cmd=f\"Input Timeseries: {os.path.basename(cii)}\")\n\u001b[1;32m      3\u001b[0m [log_msg.log(log_file=log_file, \n\u001b[1;32m      4\u001b[0m              log_cmd=f\"Processing CIFTI label file: {label}\") for label in labels ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_msg' is not defined"
     ]
    }
   ],
   "source": [
    "log_msg.log(log_file=log_file,\n",
    "            log_cmd=f\"Input Timeseries: {os.path.basename(cii)}\")\n",
    "[log_msg.log(log_file=log_file, \n",
    "             log_cmd=f\"Processing CIFTI label file: {label}\") for label in labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = 'out.1'\n",
    "o2 = 'out.2'\n",
    "o3 = 'out.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [ o1, o2, o3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-1eb37621ff2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'out.4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "out[len(out)] = 'out.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(out):\n",
    "    print(type(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.reshape(range(1,17),[4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = np.reshape(range(17,33),[4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [ t1, t2]:\n",
    "    t_l.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]]), array([[17, 18, 19, 20],\n",
       "        [21, 22, 23, 24],\n",
       "        [25, 26, 27, 28],\n",
       "        [29, 30, 31, 32]])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4, 17, 18, 19, 20],\n",
       "       [ 5,  6,  7,  8, 21, 22, 23, 24],\n",
       "       [ 9, 10, 11, 12, 25, 26, 27, 28],\n",
       "       [13, 14, 15, 16, 29, 30, 31, 32]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(t_l,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.concatenate(t_l,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
